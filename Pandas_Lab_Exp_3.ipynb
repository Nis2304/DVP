{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0ab55b7",
      "metadata": {
        "id": "a0ab55b7"
      },
      "source": [
        "# 3.a. Comprehensive Student Performance Analysis Using Pandas\n",
        "#### Problem Statement:\n",
        "\n",
        "Perform a thorough analysis of student performance across multiple subjects while handling data issues such as missing marks, duplicate entries, and inconsistent formatting. Use various Pandas functionalities to clean, organize, and derive insights from the data.\n",
        "\n",
        "#### Objective Scenario:\n",
        "\n",
        "A college stores internal assessment scores of students in an Excel/CSV file for three subjects: Math, Physics, and Chemistry. However, the dataset contains:\n",
        "\n",
        "â€¢\tMissing marks due to absent students,\n",
        "â€¢\tDuplicate entries for some students,\n",
        "â€¢\tInconsistent string formatting in names,\n",
        "â€¢\tNo unique ID assigned to students.\n",
        "\n",
        "The academic head wants to:\n",
        "\n",
        "1.\tClean and prepare the data.\n",
        "2.\tAnalyze individual and subject-wise performance.\n",
        "3.\tIdentify high-performing students and subjects with the most variability.\n",
        "\n",
        "#### Dataset:\n",
        "\n",
        "The data is stored in a CSV file named student_scores.csv, and contains the following columns:\n",
        "\n",
        "Example data:\n",
        "\n",
        "Name,Math,Physics,Chemistry\n",
        "\n",
        "Alice,78,85,\n",
        "\n",
        "Bob,82,,88\n",
        "\n",
        "Charlie,75,79,91\n",
        "\n",
        "Alice,78,85,\n",
        "\n",
        "David,,92,87\n",
        "\n",
        "Eve,85,84,88\n",
        "\n",
        "Bob,82,,88\n",
        "\n",
        "#### Tasks to be Performed:\n",
        "\n",
        "ðŸ”¹ Data Loading and Inspection\n",
        "\n",
        "â€¢\tLoad the dataset using Pandas from the CSV file.\n",
        "â€¢\tDisplay basic information about the dataset using .info() and .describe().\n",
        "â€¢\tCount the number of missing entries in each subject column.\n",
        "â€¢\tDetect and display duplicate rows based on student names.\n",
        "\n",
        "ðŸ”¹ Data Cleaning\n",
        "\n",
        "â€¢\tRemove duplicate entries while keeping only the first occurrence of each student.\n",
        "â€¢\tReplace missing subject scores with the median of that subject using .fillna().\n",
        "â€¢\tAssign a new unique identifier column StudentID starting from 1.\n",
        "\n",
        "ðŸ”¹ Data Transformation and Normalization\n",
        "\n",
        "â€¢\tAdd a new column TotalMarks which sums the marks of all three subjects for each student.\n",
        "â€¢\tCreate another column AverageMarks as total marks divided by the number of subjects.\n",
        "â€¢\tApply min-max normalization on all three subject scores to scale them between 0 and 1, and store them in new columns: Math_Norm, Physics_Norm, Chemistry_Norm.\n",
        "\n",
        "ðŸ”¹ Statistical and Performance Analysis\n",
        "\n",
        "â€¢\tCalculate the mean, median, and standard deviation for each subject using normalized scores.\n",
        "â€¢\tIdentify the subject with the highest standard deviation (i.e., the most variable scores).\n",
        "â€¢\tIdentify the top 3 students based on their average marks.\n",
        "â€¢\tDisplay subject-wise average performance using a pivot table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f19b63a",
      "metadata": {
        "id": "6f19b63a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb20813-3e1b-4abd-cbc0-49e1e3e4848f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Dataset Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7 entries, 0 to 6\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Name       7 non-null      object \n",
            " 1   Math       6 non-null      float64\n",
            " 2   Physics    5 non-null      float64\n",
            " 3   Chemistry  5 non-null      float64\n",
            "dtypes: float64(3), object(1)\n",
            "memory usage: 356.0+ bytes\n",
            "None\n",
            "\n",
            "--- Dataset Description ---\n",
            "           Math    Physics  Chemistry\n",
            "count   6.00000   5.000000   5.000000\n",
            "mean   80.00000  85.000000  88.400000\n",
            "std     3.63318   4.636809   1.516575\n",
            "min    75.00000  79.000000  87.000000\n",
            "25%    78.00000  84.000000  88.000000\n",
            "50%    80.00000  85.000000  88.000000\n",
            "75%    82.00000  85.000000  88.000000\n",
            "max    85.00000  92.000000  91.000000\n",
            "\n",
            "Missing values per subject:\n",
            "Math         1\n",
            "Physics      2\n",
            "Chemistry    2\n",
            "dtype: int64\n",
            "\n",
            "Duplicate Entries:\n",
            "     Name  Math  Physics  Chemistry\n",
            "0  Alice  78.0     85.0        NaN\n",
            "1    Bob  82.0      NaN       88.0\n",
            "3  Alice  78.0     85.0        NaN\n",
            "6    Bob  82.0      NaN       88.0\n",
            "\n",
            "--- Cleaned Data ---\n",
            "   StudentID     Name  Math  Physics  Chemistry\n",
            "0          1    Alice  78.0     85.0       88.0\n",
            "1          2      Bob  82.0     84.5       88.0\n",
            "2          3  Charlie  75.0     79.0       91.0\n",
            "4          4    David  80.0     92.0       87.0\n",
            "5          5      Eve  85.0     84.0       88.0\n",
            "\n",
            "--- Data with Normalized Scores ---\n",
            "   StudentID     Name  Math  Physics  Chemistry  TotalMarks  AverageMarks  \\\n",
            "0          1    Alice  78.0     85.0       88.0       251.0     83.666667   \n",
            "1          2      Bob  82.0     84.5       88.0       254.5     84.833333   \n",
            "2          3  Charlie  75.0     79.0       91.0       245.0     81.666667   \n",
            "4          4    David  80.0     92.0       87.0       259.0     86.333333   \n",
            "5          5      Eve  85.0     84.0       88.0       257.0     85.666667   \n",
            "\n",
            "   Math_Norm  Physics_Norm  Chemistry_Norm  \n",
            "0        0.3      0.461538            0.25  \n",
            "1        0.7      0.423077            0.25  \n",
            "2        0.0      0.000000            1.00  \n",
            "4        0.5      1.000000            0.00  \n",
            "5        1.0      0.384615            0.25  \n",
            "\n",
            "--- Normalized Score Statistics ---\n",
            "                     Mean    Median    StdDev\n",
            "Math_Norm       0.500000  0.500000  0.380789\n",
            "Physics_Norm    0.453846  0.423077  0.357092\n",
            "Chemistry_Norm  0.350000  0.250000  0.379144\n",
            "\n",
            "Most variable subject (highest StdDev): Math_Norm\n",
            "\n",
            "Top 3 Students:\n",
            "    StudentID   Name  AverageMarks\n",
            "4          4  David     86.333333\n",
            "5          5    Eve     85.666667\n",
            "1          2    Bob     84.833333\n",
            "\n",
            "--- Subject-wise Average Performance ---\n",
            "            Marks\n",
            "Subject         \n",
            "Chemistry   88.4\n",
            "Math        80.0\n",
            "Physics     84.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2519278286.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Math\"].fillna(df[\"Math\"].median(), inplace=True)\n",
            "/tmp/ipython-input-2519278286.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Physics\"].fillna(df[\"Physics\"].median(), inplace=True)\n",
            "/tmp/ipython-input-2519278286.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"Chemistry\"].fillna(df[\"Chemistry\"].median(), inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# -----------------------------------------\n",
        "# ðŸ”¹ 1. Data Loading and Inspection\n",
        "# -----------------------------------------\n",
        "# Load dataset from CSV\n",
        "df = pd.read_csv(\"/content/student_scores.csv\")\n",
        "\n",
        "print(\"\\n--- Dataset Info ---\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n--- Dataset Description ---\")\n",
        "print(df.describe())\n",
        "\n",
        "# Count missing values per subject\n",
        "print(\"\\nMissing values per subject:\")\n",
        "print(df[[\"Math\", \"Physics\", \"Chemistry\"]].isna().sum())\n",
        "\n",
        "# Detect duplicates based on Name\n",
        "duplicates = df[df.duplicated(subset=[\"Name\"], keep=False)]\n",
        "print(\"\\nDuplicate Entries:\\n\", duplicates)\n",
        "\n",
        "# -----------------------------------------\n",
        "# ðŸ”¹ 2. Data Cleaning\n",
        "# -----------------------------------------\n",
        "# Remove duplicates (keep first occurrence)\n",
        "df = df.drop_duplicates(subset=[\"Name\"], keep=\"first\")\n",
        "\n",
        "# Replace missing scores with median of that subject\n",
        "df[\"Math\"].fillna(df[\"Math\"].median(), inplace=True)\n",
        "df[\"Physics\"].fillna(df[\"Physics\"].median(), inplace=True)\n",
        "df[\"Chemistry\"].fillna(df[\"Chemistry\"].median(), inplace=True)\n",
        "\n",
        "# Assign unique StudentID\n",
        "df.insert(0, \"StudentID\", range(1, len(df) + 1))\n",
        "\n",
        "print(\"\\n--- Cleaned Data ---\")\n",
        "print(df)\n",
        "\n",
        "# -----------------------------------------\n",
        "# ðŸ”¹ 3. Data Transformation & Normalization\n",
        "# -----------------------------------------\n",
        "# Total and Average Marks\n",
        "df[\"TotalMarks\"] = df[[\"Math\", \"Physics\", \"Chemistry\"]].sum(axis=1)\n",
        "df[\"AverageMarks\"] = df[\"TotalMarks\"] / 3\n",
        "\n",
        "# Min-Max Normalization\n",
        "scaler = MinMaxScaler()\n",
        "df[[\"Math_Norm\", \"Physics_Norm\", \"Chemistry_Norm\"]] = scaler.fit_transform(\n",
        "    df[[\"Math\", \"Physics\", \"Chemistry\"]]\n",
        ")\n",
        "\n",
        "print(\"\\n--- Data with Normalized Scores ---\")\n",
        "print(df)\n",
        "\n",
        "# -----------------------------------------\n",
        "# ðŸ”¹ 4. Statistical & Performance Analysis\n",
        "# -----------------------------------------\n",
        "# Mean, Median, Std for normalized scores\n",
        "stats = {\n",
        "    \"Mean\": df[[\"Math_Norm\", \"Physics_Norm\", \"Chemistry_Norm\"]].mean(),\n",
        "    \"Median\": df[[\"Math_Norm\", \"Physics_Norm\", \"Chemistry_Norm\"]].median(),\n",
        "    \"StdDev\": df[[\"Math_Norm\", \"Physics_Norm\", \"Chemistry_Norm\"]].std()\n",
        "}\n",
        "stats_df = pd.DataFrame(stats)\n",
        "print(\"\\n--- Normalized Score Statistics ---\\n\", stats_df)\n",
        "\n",
        "# Subject with highest variability\n",
        "most_variable_subject = stats_df[\"StdDev\"].idxmax()\n",
        "print(\"\\nMost variable subject (highest StdDev):\", most_variable_subject)\n",
        "\n",
        "# Top 3 students by average marks\n",
        "top_students = df.nlargest(3, \"AverageMarks\")[[\"StudentID\", \"Name\", \"AverageMarks\"]]\n",
        "print(\"\\nTop 3 Students:\\n\", top_students)\n",
        "\n",
        "# Subject-wise average performance (pivot table)\n",
        "pivot_avg = df[[\"Name\", \"Math\", \"Physics\", \"Chemistry\"]].melt(id_vars=[\"Name\"],\n",
        "                                                               var_name=\"Subject\",\n",
        "                                                               value_name=\"Marks\")\n",
        "pivot_table = pivot_avg.pivot_table(index=\"Subject\", values=\"Marks\", aggfunc=\"mean\")\n",
        "print(\"\\n--- Subject-wise Average Performance ---\\n\", pivot_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62e96f76",
      "metadata": {
        "id": "62e96f76"
      },
      "source": [
        "\n",
        "\n",
        "# Exercise 3.b: Movie Ratings Aggregation and Review Analysis\n",
        "#### Problem Statement:\n",
        "Analyze movie ratings and review text data to find average ratings, detect duplicates, and extract insights using string operations.\n",
        "\n",
        "#### Objective Scenario:\n",
        "A streaming platform wants to analyze user reviews. The dataset contains user IDs, movie titles, ratings, and review comments. Some reviews are duplicated and some comments contain extra whitespace or punctuation noise.\n",
        "\n",
        "#### Dataset:\n",
        "\n",
        "Stored in movie_reviews.csv with the columns:\n",
        "\n",
        "Sample Data:\n",
        "\n",
        "UserID,MovieTitle,Rating,ReviewText\n",
        "\n",
        "U001,Inception,4.5,\"Amazing movie!\"\n",
        "\n",
        "U002,Inception,4.0,\"  brilliant  \"\n",
        "\n",
        "U001,Inception,4.5,\"Amazing movie!\"\n",
        "\n",
        "U003,Interstellar,5.0,\"Mind-blowing!\"\n",
        "\n",
        "U004,Interstellar,, \"Outstanding visuals.\"\n",
        "\n",
        "U005,Inception,4.2,\"Good plot but confusing\"\n",
        "\n",
        "#### Tasks to be Performed:\n",
        "\n",
        "ðŸ”¹ Cleaning and Preprocessing\n",
        "\n",
        "â€¢\tRemove duplicate reviews based on UserID and MovieTitle.\n",
        "â€¢\tHandle missing ratings by filling with average rating per movie.\n",
        "â€¢\tStrip and lowercase all review text using vectorized string operations.\n",
        "\n",
        "ðŸ”¹ Aggregation\n",
        "\n",
        "â€¢\tGroup by MovieTitle and calculate mean, median, and count of ratings.\n",
        "â€¢\tIdentify the top-rated movie.\n",
        "\n",
        "ðŸ”¹ Text Analysis\n",
        "\n",
        "â€¢\tCount how many times the word â€œamazingâ€ appears in all reviews.\n",
        "â€¢\tFilter reviews where rating is above 4.0 and review contains the word â€œplotâ€.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ------------------------------------\n",
        "# ðŸ”¹ 1. Load Data\n",
        "# ------------------------------------\n",
        "df = pd.read_csv(\"/content/movie_reviews.csv\")\n",
        "\n",
        "print(\"\\n--- Original Data ---\")\n",
        "print(df)\n",
        "\n",
        "# ------------------------------------\n",
        "# ðŸ”¹ Cleaning & Preprocessing\n",
        "# ------------------------------------\n",
        "# Remove duplicates based on UserID & MovieTitle (keep first occurrence)\n",
        "df = df.drop_duplicates(subset=[\"UserID\", \"MovieTitle\"], keep=\"first\")\n",
        "\n",
        "# Fill missing ratings with movie-wise average\n",
        "df[\"Rating\"] = df.groupby(\"MovieTitle\")[\"Rating\"].transform(\n",
        "    lambda x: x.fillna(x.mean())\n",
        ")\n",
        "\n",
        "# Strip extra whitespace & lowercase review text\n",
        "df[\"ReviewText\"] = df[\"ReviewText\"].str.strip().str.lower()\n",
        "\n",
        "print(\"\\n--- Cleaned Data ---\")\n",
        "print(df)\n",
        "\n",
        "# ------------------------------------\n",
        "# ðŸ”¹ Aggregation\n",
        "# ------------------------------------\n",
        "movie_stats = df.groupby(\"MovieTitle\")[\"Rating\"].agg([\"mean\", \"median\", \"count\"])\n",
        "top_rated_movie = movie_stats[\"mean\"].idxmax()\n",
        "\n",
        "print(\"\\n--- Movie Statistics ---\")\n",
        "print(movie_stats)\n",
        "print(\"\\nTop Rated Movie:\", top_rated_movie)\n",
        "\n",
        "# ------------------------------------\n",
        "# ðŸ”¹ Text Analysis\n",
        "# ------------------------------------\n",
        "# Count occurrences of \"amazing\" in all reviews\n",
        "amazing_count = df[\"ReviewText\"].str.count(r\"\\bamazing\\b\").sum()\n",
        "\n",
        "# Filter reviews with rating > 4.0 and containing \"plot\"\n",
        "plot_reviews = df[\n",
        "    (df[\"Rating\"] > 4.0) &\n",
        "    (df[\"ReviewText\"].str.contains(\"plot\", case=False, na=False))\n",
        "]\n",
        "\n",
        "print(\"\\nOccurrences of 'amazing':\", amazing_count)\n",
        "print(\"\\nReviews with rating > 4.0 and containing 'plot':\")\n",
        "print(plot_reviews)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QvELlBnsFlt",
        "outputId": "0b790350-d67a-4a50-e530-c03ad768857c"
      },
      "id": "5QvELlBnsFlt",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Original Data ---\n",
            "  UserID    MovieTitle  Rating               ReviewText\n",
            "0   U001     Inception     4.5           Amazing movie!\n",
            "1   U002     Inception     4.0               brilliant \n",
            "2   U001     Inception     4.5           Amazing movie!\n",
            "3   U003  Interstellar     5.0            Mind-blowing!\n",
            "4   U004  Interstellar     NaN     Outstanding visuals.\n",
            "5   U005     Inception     4.2  Good plot but confusing\n",
            "\n",
            "--- Cleaned Data ---\n",
            "  UserID    MovieTitle  Rating               ReviewText\n",
            "0   U001     Inception     4.5           amazing movie!\n",
            "1   U002     Inception     4.0                brilliant\n",
            "3   U003  Interstellar     5.0            mind-blowing!\n",
            "4   U004  Interstellar     5.0     outstanding visuals.\n",
            "5   U005     Inception     4.2  good plot but confusing\n",
            "\n",
            "--- Movie Statistics ---\n",
            "                  mean  median  count\n",
            "MovieTitle                           \n",
            "Inception     4.233333     4.2      3\n",
            "Interstellar  5.000000     5.0      2\n",
            "\n",
            "Top Rated Movie: Interstellar\n",
            "\n",
            "Occurrences of 'amazing': 1\n",
            "\n",
            "Reviews with rating > 4.0 and containing 'plot':\n",
            "  UserID MovieTitle  Rating               ReviewText\n",
            "5   U005  Inception     4.2  good plot but confusing\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}